
In this blog post, I detail my experience creating a class of **Country Year** objects for all real countries in all years and storing my work in a CSV.

When starting this lab, I created the class, as shown here:

```python
class CountryYear:
   def __init__(self, country, country_iso3, year, **indicators):
       self.country = country
       self.country_iso3 = country_iso3
       self.year = year
       self.indicators = indicators
```

However, my initial thought process was to access the endpoint `country/(country’s iso3 code)/indicator/(the indicator)`. I then created a program that would loop through this process with each indicator, sending a new API request each time. I then realized that to actually accomplish this method, I need to input a country’s iso3 code, but to get a list of iso3 codes, I had to send yet another API request with the `/country` endpoint. After also looping through each year from 2000 to 2023, the amount of API requests this method requires is 8 (number of indicators) multiplied by 23 (number of years) multiplied by the number of countries. Unsurprisingly, I found that generating a CSV for every country from the years 2000-2023 took a whopping 5 hours (when it worked). I wasn’t even accounting for the years before 2000.

In an attempt to find a more efficient method instead of manually looping through each individual country, year, and indicator, I encountered the `all/indicator/(the indicator)` endpoint, where simply inputting one indicator code gives the complete list of all countries through all years and their respective indicator values, along with helpful information like the country’s name, year, and iso3 code which I needed to create a **Country Year** object. When first implementing this new endpoint, I did not even use a class at first, I simply sent an API request for each indicator which also returned the country year attributes like iso3 code, and just created another method which combined all indicator values for each country and year. The function returned a single list of dictionaries which I used to write my CSV. To modify accounting for the **CountryYear** class, I simply modified my second function to return a list of **Country Year** objects.

In my final CSV, I noticed that a large amount of the “countries” weren’t actually countries. For example, it was very interesting to see “Middle Income” and “Not Classified” in the list of countries. However, I also noticed that the way the API endpoint ordered the countries was very “nice.” These fake countries started at the beginning of the list, and ended right before “Afghanistan.” After determining the start index, I just removed the first 3135 entries by splicing the list at entry 3136 and beyond. I guess this did require it to be “hardcoded” as I saw the output of the code and manually set the indices to not be included. If I had more time, in order to make it more efficient and accessible, I would first remove “countries” without iso3 code values, and then use the `/countries` to store all countries with an “Aggregates” value, or do not have any values for the capital city. For example, this is the raw JSON for “Africa Eastern and Southern,” which is not a country:

```json
"id": "AFE",
"iso2Code": "ZH",
"name": "Africa Eastern and Southern",
"region": {
    "id": "NA",
    "iso2code": "NA",
    "value": "Aggregates"
},
"adminregion": {
    "id": "",
    "iso2code": "",
    "value": ""
},
"incomeLevel": {
    "id": "NA",
    "iso2code": "NA",
    "value": "Aggregates"
},
"lendingType": {
    "id": "",
    "iso2code": "",
    "value": "Aggregates"
},
"capitalCity": "",
"longitude": "",
"latitude": ""
```

Clearly, a lot of values that normal countries have are not filled in here.

Finally, just talking about which indicators I used, I initially picked these five indicators:

- `life_expectancy`: `SP.DYN.LE00.IN`, Life expectancy
- `gdp_per_capita`: `NY.GDP.PCAP.CD`, GDP per capita
- `population`: `SP.POP.TOTL`, Population
- `forest_area`: `AG.LND.FRST.ZS`, Forest area (% of land area)
- `fossil_fuel_energy_consumption`: `EN.ATM.CO2E.KT`, Fossil fuel energy consumption
- `population_living_in_slums`: `SH.DYN.SLUM.UR`, Slum population (%)
- `agricultural_land`: `AG.LND.AGRI.ZS`, Agricultural land (% of land area)
- `inflation_consumer_prices`: `FP.CPI.TOTL.ZG` Inflation rate

However, in my first inefficient program, I noticed that the “fossil fuel energy consumption” and the “population living in slums” indicators had very low amounts of data with respect to the **Country Years**. It was rare to see these indicator values filled in. Then, with my second program using `/all/indicator/`, the endpoint fully failed to retrieve any data for these two indicators specifically. My best guess is that because there is so little data, there is no endpoint that corresponds specifically to these two indicators. I changed those indicators to “total labor force” and “urban population,” and this issue was resolved.

In conclusion, I created a program that retrieves indicator data on every valid country for every year that data was collected. I want the most amount of data points as possible for testing for correlation, and I believe that testing for all years and all valid countries is the best way to do this. Thanks for reading!
